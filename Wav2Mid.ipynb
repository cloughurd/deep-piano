{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Mid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPwNdDt0N77NfGqqhz5tAcj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloughurd/deep-piano/blob/master/Wav2Mid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_5dTPrhCTz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Pulling ideas from https://github.com/jsleep/wav2mid\n",
        "## Data from http://www.tsi.telecom-paristech.fr/aao/en/2010/07/08/maps-database-a-piano-database-for-multipitch-estimation-and-automatic-transcription-of-music/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZZDXJ73Dt5T",
        "colab_type": "code",
        "outputId": "4ff63418-f5ef-4557-c0d5-00e2f35041f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_dir = '/content/gdrive/My Drive/Winter 2020/DL/models/'\n",
        "data_dir = '/content/gdrive/My Drive/Winter 2020/DL/data/'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEb63KBTCeCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Downloads full maps dataset\n",
        "!wget https://amubox.univ-amu.fr/s/iNG0xc5Td1Nv4rR/download\n",
        "\n",
        "## Downloads maps subset\n",
        "# !wget http://students.cs.byu.edu/~bclough/maps.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YQm_n61F2SJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Unzips the full maps dataset\n",
        "!unzip -q download\n",
        "!rm download\n",
        "!mkdir data\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "for filename in os.listdir('MAPS/'):\n",
        "  if 'zip' in filename:\n",
        "    with ZipFile('MAPS/' + filename, 'r') as z:\n",
        "      z.extractall('data/' + filename.split('.')[0])\n",
        "\n",
        "!rm -r MAPS/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTerTCwmu0Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Unzips maps subset from mounted drive\n",
        "!unzip -q /content/gdrive/My\\ Drive/Winter\\ 2020/DL/data/maps.zip -d /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVAuZzxGPyDq",
        "colab_type": "code",
        "outputId": "8e90b602-8594-4f78-e82a-1fd60e50c732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "!pip3 install torch \n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "!pip3 install pysoundfile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pysoundfile in /usr/local/lib/python3.6/dist-packages (0.9.0.post1)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from pysoundfile) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->pysoundfile) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7gdlBZMQDqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1QUA2yPRLje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lowest_key = 21\n",
        "highest_key = 108\n",
        "octave_size = 12\n",
        "desired_sr = 22050\n",
        "window_size = 7\n",
        "pretty_midi.pretty_midi.MAX_TICK = 1e10\n",
        "\n",
        "def wav_to_input(fn, bin_multiple=3):\n",
        "  bins_per_octave = bin_multiple * octave_size\n",
        "  num_bins = (highest_key+1 - lowest_key) * bin_multiple\n",
        "  \n",
        "  audio, _ = librosa.load(fn, desired_sr)\n",
        "  cqt = librosa.cqt(audio, desired_sr, fmin=librosa.midi_to_hz(lowest_key), bins_per_octave=bins_per_octave, n_bins=num_bins)\n",
        "  del audio\n",
        "  cqt = cqt.T # Puts time dim first\n",
        "  cqt = np.abs(cqt)\n",
        "  min_fq = np.min(cqt)\n",
        "  cqt = np.pad(cqt, ((window_size//2, window_size//2),(0,0)), 'constant', constant_values=min_fq)\n",
        "\n",
        "  # This sets up a matrix where at each time step we have a 7 (window_size) frame snippet from which to pull piano pitches\n",
        "  windows = []\n",
        "  for i in range(len(cqt) - window_size + 1):\n",
        "    windows.append(cqt[i:i+window_size, :])\n",
        "  cqt = np.array(windows)\n",
        "  return cqt\n",
        "\n",
        "def midi_to_output(midi, x):\n",
        "  times = librosa.frames_to_time(np.arange(len(x)), desired_sr)\n",
        "  roll = midi.get_piano_roll(desired_sr, times)\n",
        "  roll = roll[lowest_key: highest_key+1]\n",
        "  roll = roll.T # Puts time dim first\n",
        "  roll[roll > 0] = 1\n",
        "  return roll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poxthy_fNbUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MapsDataset(Dataset):\n",
        "  def __init__(self, root, chunk_size=600, subset=True):\n",
        "    if subset:\n",
        "      self.wav_files = glob.glob(root + '*.wav')\n",
        "    else:\n",
        "      self.wav_files = glob.glob(root + '*/*/MUS/MAPS_MUS*.wav')\n",
        "    self.chunk_size = chunk_size\n",
        "  def __getitem__(self, i):\n",
        "    # x, sr = sf.read(self.wav_files[i])\n",
        "    x = wav_to_input(self.wav_files[i])\n",
        "    midi_filename = self.wav_files[i].split('.')[0] + '.mid'\n",
        "    y = pretty_midi.PrettyMIDI(midi_filename)\n",
        "    y = midi_to_output(y, x)\n",
        "    if len(y) <= self.chunk_size:\n",
        "      return x, y\n",
        "    start = random.randint(0, len(y)-self.chunk_size)\n",
        "    x = x[start:start+self.chunk_size, :]\n",
        "    y = y[start:start+self.chunk_size, :]\n",
        "    return x, y\n",
        "  def __len__(self):\n",
        "    return len(self.wav_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IySlWLJL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MapsDataset('MAPS_MUS/')\n",
        "loader = DataLoader(dataset, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOCcLtFrw0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_c, out_c, kernel_size=3, padding=1):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_c, out_c, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.Dropout2d()\n",
        "    )\n",
        "    if in_c != out_c:\n",
        "      self.skip = nn.Conv2d(in_c, out_c, kernel_size=1)\n",
        "    else:\n",
        "      self.skip = nn.Identity()\n",
        "    self.final = nn.ReLU()\n",
        "  def forward(self, x):\n",
        "    res = self.net(x)\n",
        "    y = self.skip(x) + res\n",
        "    return self.final(y)\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        ConvBlock(1, 3),\n",
        "        ConvBlock(3, 8),\n",
        "        ConvBlock(8, 8),\n",
        "        ConvBlock(8, 16),\n",
        "        nn.MaxPool2d((1, 2)),\n",
        "        ConvBlock(16, 16),\n",
        "        ConvBlock(16, 32),\n",
        "        ConvBlock(32, 32),\n",
        "        ConvBlock(32, 64),\n",
        "        nn.MaxPool2d((1, 2)),\n",
        "        ConvBlock(64, 64),\n",
        "        ConvBlock(64, 64),\n",
        "        ConvBlock(64, 64),\n",
        "        nn.MaxPool2d((1, 2)),\n",
        "        ConvBlock(64, 128),\n",
        "        ConvBlock(128, 128),\n",
        "        nn.AvgPool2d((7, 33))\n",
        "    )\n",
        "    self.final = nn.Sequential(\n",
        "        nn.Linear(128, 88),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    y = self.net(x)\n",
        "    y = y.squeeze(2).squeeze(2)\n",
        "    return self.final(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw-RIT5O15B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net().cuda()\n",
        "# net = torchvision.models.resnet50(pretrained=True)\n",
        "# num_f = net.fc.in_features\n",
        "# net.fc = nn.Sequential(\n",
        "#     nn.Linear(num_f, 88),\n",
        "#     torch.Sigmoid()\n",
        "# )\n",
        "# net = net.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=3e-3)\n",
        "objective = nn.BCELoss(reduction='sum')\n",
        "losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXQxN1kd2Oq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs=25, save_freq=1):\n",
        "  for i in range(num_epochs):\n",
        "    loop = tqdm(total=len(loader), position=0, leave=False)\n",
        "    for x, y in loader:\n",
        "      x = x.squeeze(0).unsqueeze(1).float().cuda()\n",
        "      y = y.squeeze(0).cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_hat = net(x)\n",
        "      loss = objective(y_hat, y.float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      losses.append(loss.item())      \n",
        "      \n",
        "      loop.set_description('epoch:{}, loss:{:.4f}'.format(i, loss.item()))\n",
        "      loop.update(1)\n",
        "      \n",
        "    if i % save_freq == 0:\n",
        "      torch.save(net, model_dir + 'transcriber' + str(i) + '.mod')\n",
        "  return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_7RQYGLFx4R",
        "colab_type": "code",
        "outputId": "43cf94bf-a1be-49a2-dfd4-d740c63fec1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train()\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0, loss:7455.4170:  92%|█████████▏| 138/150 [58:10<05:58, 29.88s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY5NNzBiulj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}